#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Enhanced Symbol Filter: ÙÛŒÙ„ØªØ± Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±
"""

import pandas as pd
import logging
import os
import json
from datetime import date
import argparse
from typing import Optional

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class EnhancedSymbolFilter:
    """
    ÙÛŒÙ„ØªØ± Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„
    Ø¨Ø± Ø§Ø³Ø§Ø³:
    - Ù†ÙˆØ¹ Ù†Ù…Ø§Ø¯ (Ø³Ù‡Ø§Ù… Ø¹Ø§Ø¯ÛŒ ÙÙ‚Ø·)
    - ÙØ¹Ø§Ù„ÛŒØª (Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª)
    - Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ù‚ØªØµØ§Ø¯ÛŒ (P/E, EPS)
    """
    
    # Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ ØºÛŒØ±Ù…Ø¹ØªØ¨Ø±
    INVALID_KEYWORDS = {
        'warrant_rights': ['Ø¯', 'Ù€Ø±', 'Ù€Ø­', 'Ø­Ù‚'],
        'funds_etf': ['ØµÙ†Ø¯ÙˆÙ‚', 'ETF', 'Ø´Ø§Ø®ØµÛŒ'],
        'bonds': ['ØµÚ©ÙˆÙƒ', 'Ø§ÙˆØ±Ø§Ù‚', 'Ø¯Ø±Ø¢Ù…Ø¯ Ø«Ø§Ø¨Øª', 'Ø¨Ø¯Ù‡ÛŒ'],
        'murabaha': ['Ù…Ø±Ø§Ø¨Ø­Ù‡'],
        'housing': ['Ù…Ø³Ú©Ù†', 'ØªØ³'],
        'forex_crypto': ['Ø§Ø±Ø²', 'ØªØ§Ù„Ø§Ø±', 'Ú©Ø±ÛŒÙ¾ØªÙˆ'],
        'inactive': ['Ø­Ø°Ù', 'ØªØ¹Ù„ÛŒÙ‚', 'Ù…Ø¹Ù„Ù‚', 'ØºÛŒØ±ÙØ¹Ø§Ù„'],
        'government': ['Ø¯ÙˆÙ„ØªÛŒ', 'Ø®Ø²Ø§Ù†Ù‡', 'Ø§Ø³Ù„Ø§Ù…ÛŒ'],
        'real_estate': ['Ø§Ù…Ù„Ø§Ú©', 'Ù…Ø³ØªØºÙ„Ø§Øª', 'Ø³Ø±Ù…Ø§ÛŒÙ‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ'],
        'investment': ['Øµ.Ø³.', 'Ø³Ø±Ù…Ø§ÛŒÙ‡ Ú¯Ø°Ø§Ø±ÛŒ', 'Ø³Ø±Ù…Ø§ÛŒÙ‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ'],
    }
    
    # Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ ØµÙ†Ø¹ØªÛŒ Ù…Ø¹ØªØ¨Ø±
    VALID_SECTORS = [
        'Ø³ÛŒÙ…Ø§Ù†', 'ÙÙˆÙ„Ø§Ø¯', 'Ø®ÙˆØ¯Ø±Ùˆ', 'Ù¾ØªØ±ÙˆØ´ÛŒÙ…ÛŒ', 'Ù†ÙØª', 'Ú¯Ø§Ø²',
        'Ø¨Ø§Ù†Ú©', 'Ø¨ÛŒÙ…Ù‡', 'Ù…ÙˆØ§Ø¯', 'Ù…Ø¹Ø§Ø¯Ù†', 'Ø§Ù„ÙˆÙ…ÛŒÙ†ÛŒÙˆÙ…', 'Ù…Ø³',
        'Ø§Ù†Ø±Ú˜ÛŒ', 'Ø¨Ø±Ù‚', 'Ø¢Ø¨', 'Ù…Ø®Ø§Ø¨Ø±Ø§Øª', 'Ø¯Ø§Ø±Ùˆ', 'ØºØ°Ø§',
        'Ø´ÛŒØ±', 'Ú©Ø´Ø§ÙˆØ±Ø²ÛŒ', 'Ø®Ø¯Ù…Ø§Øª', 'Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ', 'Ø­Ù…Ù„ Ùˆ Ù†Ù‚Ù„',
        'ØµÙ†Ø¹ØªÛŒ', 'Ø¹Ù…ÙˆÙ…ÛŒ', 'Ø´ÛŒÙ…ÛŒ', 'Ø±ÛŒØ®ØªÙ‡â€ŒÚ¯Ø±ÛŒ', 'Ù†Ø³Ø§Ø¬ÛŒ',
        'Ø³Ø±Ø§Ù…ÛŒÚ©', 'Ú©Ø§Ø´ÛŒ', 'Ø´ÛŒØ´Ù‡', 'Ú†ÛŒÙ†ÛŒ', 'Ø³Ø§Ø²Ù‡â€ŒØ§ÛŒ'
    ]
    
    def __init__(self):
        self.filters_applied = {}
        self.removed_symbols = []
    
    def check_invalid_keywords(self, symbol: str, name: str) -> tuple[bool, str]:
        """Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±"""
        symbol_full = f"{symbol} {name}".upper()
        
        for category, keywords in self.INVALID_KEYWORDS.items():
            for keyword in keywords:
                if keyword in symbol_full:
                    return False, f"[{category}] {keyword}"
        
        return True, ""
    
    def check_valid_sector(self, name: str) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒØ§ Ø¨Ø®Ø´ ØµÙ†Ø¹ØªÛŒ Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª"""
        name_upper = name.upper()
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ù†Ø§Ù… Ø´Ø§Ù…Ù„ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© Ø¨Ø®Ø´ Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª
        for sector in self.VALID_SECTORS:
            if sector in name_upper:
                return True
        
        return False
    
    def check_numeric_validity(self, row: pd.Series) -> tuple[bool, str]:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ"""
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª
        try:
            volume = pd.to_numeric(row.get('Ø­Ø¬Ù…', 0), errors='coerce')
            if pd.isna(volume) or volume <= 0:
                return False, "Ø­Ø¬Ù… ØµÙØ± ÛŒØ§ Ù†Ø§Ù…Ø¹ØªØ¨Ø±"
        except:
            pass
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù‚ÛŒÙ…Øª Ø¢Ø®Ø±ÛŒÙ† Ù…Ø¹Ø§Ù…Ù„Ù‡
        try:
            last_price = pd.to_numeric(row.get('Ø¢Ø®Ø±ÛŒÙ† Ù…Ø¹Ø§Ù…Ù„Ù‡ - Ù…Ù‚Ø¯Ø§Ø±', 0), errors='coerce')
            if pd.isna(last_price) or last_price <= 100:
                return False, "Ù‚ÛŒÙ…Øª Ø¨Ø³ÛŒØ§Ø± Ù¾Ø§ÛŒÛŒÙ† ÛŒØ§ Ù†Ø§Ù…Ø¹ØªØ¨Ø±"
        except:
            pass
        
        return True, ""
    
    def filter_symbols(self, df: pd.DataFrame, top_n: int = 20) -> pd.DataFrame:
        """ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø±"""
        
        valid_rows = []
        
        for idx, row in df.iterrows():
            symbol = str(row.get('Ù†Ù…Ø§Ø¯', '')).strip()
            name = str(row.get('Ù†Ø§Ù…', '')).strip()
            
            # ÙÛŒÙ„ØªØ± 1: Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±
            is_valid, reason = self.check_invalid_keywords(symbol, name)
            if not is_valid:
                self._record_removal(symbol, name, reason)
                continue
            
            # ÙÛŒÙ„ØªØ± 2: Ø¨Ø®Ø´ ØµÙ†Ø¹ØªÛŒ Ù…Ø¹ØªØ¨Ø±
            if not self.check_valid_sector(name):
                self._record_removal(symbol, name, "[sector] Ù†ÙˆØ¹ ØµÙ†Ø¹Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø±")
                continue
            
            # ÙÛŒÙ„ØªØ± 3: Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ
            is_valid, reason = self.check_numeric_validity(row)
            if not is_valid:
                self._record_removal(symbol, name, reason)
                continue
            
            valid_rows.append(idx)
        
        # Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒØ¯ Ù…ÙˆØ§Ø±Ø¯ Ù…Ø¹ØªØ¨Ø±
        result = df.loc[valid_rows].reset_index(drop=True)
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª (Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯)
        if 'Ø­Ø¬Ù…' in result.columns:
            try:
                result['Ø­Ø¬Ù…_numeric'] = pd.to_numeric(result['Ø­Ø¬Ù…'], errors='coerce')
                result = result.sort_values('Ø­Ø¬Ù…_numeric', ascending=False, na_position='last')
                result = result.drop('Ø­Ø¬Ù…_numeric', axis=1)
            except:
                pass
        
        # Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒØ¯ Ø¨Ø±ØªØ±ÛŒÙ† N Ù†Ù…Ø§Ø¯
        return result.head(top_n).reset_index(drop=True)
    
    def _record_removal(self, symbol: str, name: str, reason: str):
        """Ø«Ø¨Øª Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø­Ø°Ùâ€ŒØ´Ø¯Ù‡"""
        self.removed_symbols.append({
            'symbol': symbol,
            'name': name,
            'reason': reason
        })
        
        if reason not in self.filters_applied:
            self.filters_applied[reason] = 0
        self.filters_applied[reason] += 1
    
    def print_report(self):
        """Ú†Ø§Ù¾ Ú¯Ø²Ø§Ø±Ø´ ÙÛŒÙ„ØªØ±"""
        total_removed = len(self.removed_symbols)
        
        logger.info("\n" + "="*80)
        logger.info("ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ ÙÛŒÙ„ØªØ± Ø´Ø¯Ú¯ÛŒ")
        logger.info("="*80)
        logger.info(f"âŒ Ú©Ù„ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡: {total_removed}")
        logger.info("\nğŸ“‹ Ø¯Ù„Ø§ÛŒÙ„ Ø­Ø°Ù:")
        
        for reason, count in sorted(self.filters_applied.items(), 
                                     key=lambda x: x[1], reverse=True):
            logger.info(f"  - {reason}: {count}")


def main():
    """Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§ØµÙ„ÛŒ"""
    
    parser = argparse.ArgumentParser(description='Enhanced symbol filter outputs')
    parser.add_argument('--project-name', default='J.M_Stock_Market', help='Project name to include in outputs')
    parser.add_argument('--contact-email', default=None, help='Contact email to embed in outputs')
    parser.add_argument('--top-n', type=int, default=20, help='Number of top symbols to keep')
    parser.add_argument('--save-pdf', action='store_true', help='Also export results to PDF if reportlab is available')
    parser.add_argument('--save-excel', action='store_true', help='Also export results to Excel')
    args = parser.parse_args()

    # if user didn't specify flags, produce both Excel and PDF by default
    if not args.save_excel and not args.save_pdf:
        args.save_excel = True
        args.save_pdf = True

    print("\n" + "="*80)
    print(f"ğŸ¯ ÙÛŒÙ„ØªØ± Ù¾ÛŒØ´Ø±ÙØªÛ€ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ ({args.project_name})")
    print("="*80 + "\n")
    
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    logger.info("ğŸ“¥ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ CSV...")
    
    try:
        df = pd.read_csv('data/indexes/symbols.csv', skiprows=2, encoding='utf-8')
        df.columns = df.columns.str.strip()
        
        logger.info(f"âœ… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÙˆÙÙ‚: {len(df)} Ù†Ù…Ø§Ø¯")
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§: {e}")
        return
    
    # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù†
    logger.info("\nğŸ” Ø§Ø¹Ù…Ø§Ù„ ÙÛŒÙ„ØªØ±Ù‡Ø§...")
    
    filter_obj = EnhancedSymbolFilter()
    top_20 = filter_obj.filter_symbols(df, top_n=args.top_n)
    
    # Ú¯Ø²Ø§Ø±Ø´
    filter_obj.print_report()
    
    # Ø°Ø®ÛŒØ±Ù‡â€ŒÛŒ ÙØ§ÛŒÙ„
    logger.info("\nğŸ’¾ Ø°Ø®ÛŒØ±Ù‡â€ŒÛŒ ÙØ§ÛŒÙ„...")
    # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Û€ Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø§ ØªØ§Ø±ÛŒØ® Ø§Ù…Ø±ÙˆØ²
    out_dir = os.path.join('outputs', date.today().isoformat())
    os.makedirs(out_dir, exist_ok=True)

    # Ù†Ø§Ù… ÙØ§ÛŒÙ„Ù‡Ø§ Ø´Ø§Ù…Ù„ Ù†Ø§Ù… Ù¾Ø±ÙˆÚ˜Ù‡ Ùˆ ØªØ§Ø±ÛŒØ®
    safe_proj = args.project_name.replace(' ', '_')
    csv_name = f"top_symbols_{safe_proj}_{date.today().isoformat()}.csv"
    top_path = os.path.join(out_dir, csv_name)
    top_20.to_csv(top_path, index=False, encoding='utf-8')
    logger.info(f"âœ… Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {top_path}\n")

    # Ø°Ø®ÛŒØ±Ù‡â€ŒÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø­Ø°Ùâ€ŒØ´Ø¯Ù‡ Ùˆ Ø®Ù„Ø§ØµÙ‡Ù” ÙÛŒÙ„ØªØ±Ù‡Ø§
    try:
        if filter_obj.removed_symbols:
            removed_df = pd.DataFrame(filter_obj.removed_symbols)
            removed_name = f"removed_symbols_{safe_proj}_{date.today().isoformat()}.csv"
            removed_path = os.path.join(out_dir, removed_name)
            removed_df.to_csv(removed_path, index=False, encoding='utf-8')
            logger.info(f"âœ… Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {removed_path}")

        # Ø°Ø®ÛŒØ±Ù‡â€ŒÛŒ Ø®Ù„Ø§ØµÙ‡Ù” ÙÛŒÙ„ØªØ±Ù‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª JSON
        filters_name = f"filters_summary_{safe_proj}_{date.today().isoformat()}.json"
        filters_path = os.path.join(out_dir, filters_name)
        with open(filters_path, 'w', encoding='utf-8') as fh:
            json.dump(filter_obj.filters_applied, fh, ensure_ascii=False, indent=2)
        logger.info(f"âœ… Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {filters_path}")

        # Ø°Ø®ÛŒØ±Ù‡Ù” Ù…ØªØ§Ø¯ÛŒØªØ§ Ø´Ø§Ù…Ù„ Ù†Ø§Ù… Ù¾Ø±ÙˆÚ˜Ù‡ Ùˆ Ø§ÛŒÙ…ÛŒÙ„ ØªÙ…Ø§Ø³
        metadata = {
            'project_name': args.project_name,
            'contact_email': args.contact_email,
            'date': date.today().isoformat(),
            'row_count': len(top_20)
        }
        metadata_path = os.path.join(out_dir, f"metadata_{safe_proj}_{date.today().isoformat()}.json")
        with open(metadata_path, 'w', encoding='utf-8') as fh:
            json.dump(metadata, fh, ensure_ascii=False, indent=2)
        logger.info(f"âœ… Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {metadata_path}")

        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Excel Ø¯Ø± ØµÙˆØ±Øª Ø¯Ø±Ø®ÙˆØ§Ø³Øª
        if args.save_excel:
            try:
                excel_name = f"top_symbols_{safe_proj}_{date.today().isoformat()}.xlsx"
                excel_path = os.path.join(out_dir, excel_name)
                with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
                    top_20.to_excel(writer, sheet_name='TopSymbols', index=False)
                    if filter_obj.removed_symbols:
                        removed_df.to_excel(writer, sheet_name='Removed', index=False)
                    # metadata sheet
                    meta_df = pd.DataFrame(list(metadata.items()), columns=['key', 'value'])
                    meta_df.to_excel(writer, sheet_name='Metadata', index=False)
                logger.info(f"âœ… Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {excel_path}")
                # add a Header sheet with project info and filters summary, styled
                try:
                    from openpyxl import load_workbook
                    from openpyxl.styles import Font

                    wb = load_workbook(excel_path)
                    # create header sheet at the front
                    if 'Header' in wb.sheetnames:
                        hdr = wb['Header']
                    else:
                        hdr = wb.create_sheet(title='Header', index=0)

                    hdr['A1'] = args.project_name
                    hdr['A2'] = f"Contact: {args.contact_email or ''}"
                    hdr['A3'] = f"Date: {date.today().isoformat()}"
                    hdr['A4'] = f"Rows: {len(top_20)}"
                    hdr['A1'].font = Font(size=14, bold=True)
                    hdr['A2'].font = Font(bold=False)

                    start_row = 6
                    hdr.cell(row=start_row, column=1, value='Filter Reason').font = Font(bold=True)
                    hdr.cell(row=start_row, column=2, value='Count').font = Font(bold=True)
                    r = start_row + 1
                    for reason, count in filter_obj.filters_applied.items():
                        hdr.cell(row=r, column=1, value=reason)
                        hdr.cell(row=r, column=2, value=count)
                        r += 1

                    wb.save(excel_path)
                except Exception as e:
                    logger.warning(f"âš ï¸ Ø®Ø·Ø§ Ù‡Ù†Ú¯Ø§Ù… Ø§ÙØ²ÙˆØ¯Ù† Ø´ÛŒØª Ø³Ø±Ø¨Ø±Ú¯ Ø¨Ù‡ Ø§Ú©Ø³Ù„: {e}")
            except Exception as e:
                logger.warning(f"âš ï¸ Ø®Ø·Ø§ Ù‡Ù†Ú¯Ø§Ù… Ø°Ø®ÛŒØ±Ù‡Ù” Ø§Ú©Ø³Ù„: {e}")

        # Ø°Ø®ÛŒØ±Ù‡ PDF Ø¯Ø± ØµÙˆØ±Øª Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ùˆ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø¨ÙˆØ¯Ù† reportlab
        if args.save_pdf:
            try:
                from reportlab.lib.pagesizes import A4
                from reportlab.lib import colors
                from reportlab.lib.styles import ParagraphStyle, getSampleStyleSheet
                from reportlab.platypus import SimpleDocTemplate, Paragraph, Table, TableStyle, Spacer
                from reportlab.pdfbase import pdfmetrics
                from reportlab.pdfbase.ttfonts import TTFont

                # Attempt to find a suitable TTF font for Persian/Arabic rendering
                def find_font_path():
                    candidates = [
                        os.path.join(os.getcwd(), 'Vazir.ttf'),
                        os.path.join(os.getcwd(), 'Vazirmatn.ttf'),
                        r'C:\Windows\Fonts\Tahoma.ttf',
                        r'C:\Windows\Fonts\Arial.ttf',
                        r'C:\Windows\Fonts\DejaVuSans.ttf',
                    ]
                    for p in candidates:
                        if p and os.path.exists(p):
                            return p
                    return None

                font_path = find_font_path()
                font_name = 'Helvetica'
                if font_path:
                    try:
                        font_name = 'CustomFont'
                        pdfmetrics.registerFont(TTFont(font_name, font_path))
                    except Exception:
                        font_name = 'Helvetica'

                pdf_name = f"top_symbols_{safe_proj}_{date.today().isoformat()}.pdf"
                pdf_path = os.path.join(out_dir, pdf_name)

                doc = SimpleDocTemplate(pdf_path, pagesize=A4, rightMargin=36, leftMargin=36, topMargin=36, bottomMargin=36)
                styles = getSampleStyleSheet()
                # override or create styles to use chosen font
                title_style = ParagraphStyle('Title', parent=styles['Title'], fontName=font_name, fontSize=16, leading=20)
                normal_style = ParagraphStyle('Normal', parent=styles['Normal'], fontName=font_name, fontSize=10, leading=12)
                heading_style = ParagraphStyle('Heading2', parent=styles.get('Heading2', styles['Normal']), fontName=font_name, fontSize=12, leading=14)

                elems = []

                # Header block
                header = f"{args.project_name}"
                elems.append(Paragraph(header, title_style))
                info_lines = [f"Date: {date.today().isoformat()}"]
                if args.contact_email:
                    info_lines.append(f"Contact: {args.contact_email}")
                for line in info_lines:
                    elems.append(Paragraph(line, normal_style))
                elems.append(Spacer(1, 12))

                elems.append(Paragraph(f"Top {len(top_20)} Symbols", heading_style))
                elems.append(Spacer(1, 6))

                # prepare table data (limited columns)
                cols = ['Ù†Ù…Ø§Ø¯', 'Ù†Ø§Ù…']
                if 'Ø­Ø¬Ù…' in top_20.columns:
                    cols.append('Ø­Ø¬Ù…')
                if 'Ø¢Ø®Ø±ÛŒÙ† Ù…Ø¹Ø§Ù…Ù„Ù‡ - Ù…Ù‚Ø¯Ø§Ø±' in top_20.columns:
                    cols.append('Ø¢Ø®Ø±ÛŒÙ† Ù…Ø¹Ø§Ù…Ù„Ù‡ - Ù…Ù‚Ø¯Ø§Ø±')

                table_data = [cols]
                for _, r in top_20[cols].iterrows():
                    row_vals = [str(r[c]) for c in cols]
                    table_data.append(row_vals)

                # calculate column widths roughly based on page width
                from reportlab.lib.pagesizes import A4 as A4_size
                page_w, page_h = A4_size
                usable_w = page_w - doc.leftMargin - doc.rightMargin
                # allocate more width to 'Ù†Ø§Ù…'
                ncols = len(cols)
                widths = []
                for c in cols:
                    if c == 'Ù†Ø§Ù…':
                        widths.append(usable_w * 0.5)
                    elif c == 'Ù†Ù…Ø§Ø¯':
                        widths.append(usable_w * 0.15)
                    else:
                        widths.append(usable_w * 0.35 / max(1, ncols-2))

                table = Table(table_data, repeatRows=1, hAlign='LEFT', colWidths=widths)
                table.setStyle(TableStyle([
                    ('BACKGROUND', (0,0), (-1,0), colors.HexColor('#d3d3d3')),
                    ('GRID', (0,0), (-1,-1), 0.5, colors.grey),
                    ('VALIGN', (0,0), (-1,-1), 'MIDDLE'),
                    ('LEFTPADDING', (0,0), (-1,-1), 6),
                    ('RIGHTPADDING', (0,0), (-1,-1), 6),
                ]))
                elems.append(table)
                doc.build(elems)
                logger.info(f"âœ… Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {pdf_path}")
            except ImportError:
                logger.warning('reportlab Ù†ØµØ¨ Ù†Ø´Ø¯Ù‡Ø› Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ PDFØŒ Ø¢Ù† Ø±Ø§ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯: pip install reportlab')
            except Exception as e:
                logger.warning(f"âš ï¸ Ø®Ø·Ø§ Ù‡Ù†Ú¯Ø§Ù… ØªÙˆÙ„ÛŒØ¯ PDF: {e}")

    except Exception as e:
        logger.warning(f"âš ï¸ Ø®Ø·Ø§ Ù‡Ù†Ú¯Ø§Ù… Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¬Ø²Ø¦ÛŒØ§Øª: {e}")
    
    # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
    print("\nğŸ“ Ø¨Ø±ØªØ±ÛŒÙ† 20 Ù†Ù…Ø§Ø¯ Ù…Ø¹ØªØ¨Ø±:\n")
    
    display_cols = ['Ù†Ù…Ø§Ø¯', 'Ù†Ø§Ù…']
    if 'Ø­Ø¬Ù…' in top_20.columns:
        display_cols.append('Ø­Ø¬Ù…')
    if 'Ø¢Ø®Ø±ÛŒÙ† Ù…Ø¹Ø§Ù…Ù„Ù‡ - Ù…Ù‚Ø¯Ø§Ø±' in top_20.columns:
        display_cols.append('Ø¢Ø®Ø±ÛŒÙ† Ù…Ø¹Ø§Ù…Ù„Ù‡ - Ù…Ù‚Ø¯Ø§Ø±')
    
    display_df = top_20[display_cols].copy()
    display_df.index = range(1, len(display_df) + 1)
    
    print(display_df.to_string())
    print("\n" + "="*80)
    print("âœ… Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!")
    print("="*80 + "\n")


if __name__ == "__main__":
    main()
